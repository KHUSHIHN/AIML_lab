{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMD6mxIdqxki6Xrq3gbWBnu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KHUSHIHN/AIML_lab/blob/main/problem_5%2C6%2C7%2C8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DBVI-iB8Rqaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60a015df-38a1-4775-c341-77d988f5efeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression - 5 Fold Accuracy = 0.953 (+/- 0.045)\n",
            "\n",
            "Logistic Regression - Confusion Matrix:\n",
            "[[50  0  0]\n",
            " [ 0 47  3]\n",
            " [ 0  4 46]]\n",
            "\n",
            "Logistic Regression - Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        50\n",
            "  versicolor       0.92      0.94      0.93        50\n",
            "   virginica       0.94      0.92      0.93        50\n",
            "\n",
            "    accuracy                           0.95       150\n",
            "   macro avg       0.95      0.95      0.95       150\n",
            "weighted avg       0.95      0.95      0.95       150\n",
            "\n",
            "Saved image: outputs/iris/cm_logistic_regression.png\n",
            "Linear SVM - 5 Fold Accuracy = 0.927 (+/- 0.053)\n",
            "\n",
            "Linear SVM - Confusion Matrix:\n",
            "[[49  1  0]\n",
            " [ 0 44  6]\n",
            " [ 0  4 46]]\n",
            "\n",
            "Linear SVM - Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      0.98      0.99        50\n",
            "  versicolor       0.90      0.88      0.89        50\n",
            "   virginica       0.88      0.92      0.90        50\n",
            "\n",
            "    accuracy                           0.93       150\n",
            "   macro avg       0.93      0.93      0.93       150\n",
            "weighted avg       0.93      0.93      0.93       150\n",
            "\n",
            "Saved image: outputs/iris/cm_linear_svm.png\n"
          ]
        }
      ],
      "source": [
        "# iris_simple_logreg_svm.py\n",
        "# Simple Logistic Regression & Linear SVM on Iris dataset\n",
        "# Includes: Standardization, 5-fold CV, Confusion Matrix, Classification Report\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "# Make output folder\n",
        "def make_output_dir():\n",
        "    os.makedirs(\"outputs/iris\", exist_ok=True)\n",
        "\n",
        "def main():\n",
        "    make_output_dir()\n",
        "\n",
        "    # Load Iris dataset\n",
        "    data = load_iris()\n",
        "    X = data.data\n",
        "    y = data.target\n",
        "    labels = data.target_names\n",
        "\n",
        "    # Define models inside a pipeline (Scaler + Classifier)\n",
        "    logistic_model = Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"clf\", LogisticRegression(max_iter=1000))\n",
        "    ])\n",
        "\n",
        "    svm_model = Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"clf\", LinearSVC())\n",
        "    ])\n",
        "\n",
        "    # 5-fold cross validation setup\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "    # Train + Evaluate both models\n",
        "    for name, model in [(\"Logistic Regression\", logistic_model),\n",
        "                        (\"Linear SVM\", svm_model)]:\n",
        "\n",
        "        # Accuracy scores for 5 folds\n",
        "        scores = cross_val_score(model, X, y, cv=cv, scoring=\"accuracy\")\n",
        "        print(f\"{name} - 5 Fold Accuracy = {scores.mean():.3f} (+/- {scores.std():.3f})\")\n",
        "\n",
        "        # Predictions using cross-validation\n",
        "        y_pred = cross_val_predict(model, X, y, cv=cv)\n",
        "\n",
        "        # Confusion Matrix\n",
        "        cm = confusion_matrix(y, y_pred)\n",
        "        print(f\"\\n{name} - Confusion Matrix:\")\n",
        "        print(cm)\n",
        "\n",
        "        # Classification report (precision, recall, f1)\n",
        "        print(f\"\\n{name} - Classification Report:\")\n",
        "        print(classification_report(y, y_pred, target_names=labels))\n",
        "\n",
        "        # Save confusion matrix plot\n",
        "        disp = ConfusionMatrixDisplay(cm, display_labels=labels)\n",
        "        disp.plot(cmap=\"Blues\")\n",
        "        plt.title(f\"{name} Confusion Matrix\")\n",
        "        out_path = f\"outputs/iris/cm_{name.replace(' ', '_').lower()}.png\"\n",
        "        plt.savefig(out_path)\n",
        "        plt.close()\n",
        "        print(f\"Saved image: {out_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "URL = \"https://raw.githubusercontent.com/justmarkham/scikit-learn-videos/master/data/sms.tsv\"\n",
        "\n",
        "def load_sms_data():\n",
        "    try:\n",
        "        print(\"Trying to download SMS dataset...\")\n",
        "        df = pd.read_csv(URL, sep=\"\\t\", header=None, names=[\"label\", \"message\"])\n",
        "        print(\"Download successful!\")\n",
        "        return df\n",
        "    except:\n",
        "        print(\"\\nCould NOT download.\")\n",
        "        print(\"Please upload SMSSpamCollection file.\")\n",
        "        from google.colab import files\n",
        "        uploaded = files.upload()\n",
        "        fname = list(uploaded.keys())[0]\n",
        "        df = pd.read_csv(fname, sep=\"\\t\", header=None, names=[\"label\", \"message\"])\n",
        "        return df\n",
        "\n",
        "def main():\n",
        "    os.makedirs(\"outputs/sms\", exist_ok=True)\n",
        "\n",
        "    df = load_sms_data()\n",
        "\n",
        "    # --------------------------\n",
        "    # ⚠ FIXED: Proper parentheses\n",
        "    # --------------------------\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        df[\"message\"],\n",
        "        df[\"label\"],\n",
        "        test_size=0.2,\n",
        "        random_state=42,\n",
        "        stratify=df[\"label\"]\n",
        "    )   # ← This ) was missing in your code!\n",
        "\n",
        "    vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
        "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "    X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "    model = LogisticRegression(max_iter=1000)\n",
        "    model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "    y_pred = model.predi_\n"
      ],
      "metadata": {
        "id": "nN6Hiv_0W_CM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mnist_mlp_vs_logistic.py\n",
        "# Keras MLP (dropout + early stopping) on MNIST, compared to a Logistic baseline.\n",
        "# Saves confusion matrix for the MLP.\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "def ensure_out():\n",
        "    os.makedirs(\"outputs/mnist\", exist_ok=True)\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    ensure_out()\n",
        "\n",
        "    # Load MNIST dataset\n",
        "    (X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "    # ----- Logistic Regression baseline -----\n",
        "    X_train_flat = X_train.reshape((X_train.shape[0], -1)).astype(\"float32\") / 255.0\n",
        "    X_test_flat = X_test.reshape((X_test.shape[0], -1)).astype(\"float32\") / 255.0\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_flat)\n",
        "    X_test_scaled = scaler.transform(X_test_flat)\n",
        "\n",
        "    logreg = LogisticRegression(\n",
        "        solver=\"saga\",\n",
        "        multi_class=\"multinomial\",\n",
        "        max_iter=200,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    logreg.fit(X_train_scaled, y_train)\n",
        "    y_pred_lr = logreg.predict(X_test_scaled)\n",
        "    acc_lr = accuracy_score(y_test, y_pred_lr)\n",
        "    print(f\"Logistic baseline test accuracy: {acc_lr:.4f}\")\n",
        "\n",
        "    # ----- MLP with dropout + early stopping -----\n",
        "    X_train_n = X_train.astype(\"float32\") / 255.0\n",
        "    X_test_n = X_test.astype(\"float32\") / 255.0\n",
        "\n",
        "    model = Sequential([\n",
        "        Flatten(input_shape=(28, 28)),\n",
        "        Dense(512, activation=\"relu\"),\n",
        "        Dropout(0.3),\n",
        "        Dense(256, activation=\"relu\"),\n",
        "        Dropout(0.3),\n",
        "        Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=\"adam\",\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    es = EarlyStopping(\n",
        "        monitor=\"val_accuracy\",\n",
        "        patience=3,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "\n",
        "    model.fit(\n",
        "        X_train_n, y_train,\n",
        "        validation_split=0.1,\n",
        "        epochs=30,\n",
        "        batch_size=128,\n",
        "        callbacks=[es],\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    test_loss, test_acc = model.evaluate(X_test_n, y_test, verbose=0)\n",
        "    print(f\"Keras MLP test accuracy: {test_acc:.4f}\")\n",
        "\n",
        "    # Confusion matrix for MLP\n",
        "    y_pred_mlp = np.argmax(model.predict(X_test_n, verbose=0), axis=1)\n",
        "    cm = confusion_matrix(y_test, y_pred_mlp)\n",
        "\n",
        "    disp = ConfusionMatrixDisplay(cm, display_labels=np.arange(10))\n",
        "    disp.plot(cmap=\"Blues\", xticks_rotation=45)\n",
        "\n",
        "    plt.title(\"MNIST Confusion Matrix - Keras MLP\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"outputs/mnist/cm_mlp.png\", dpi=200)\n",
        "    plt.close()\n",
        "\n",
        "    print(\"Saved: outputs/mnist/cm_mlp.png\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "1Kak2Lc0Zkgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# svm_kernels_margins_digits.py\n",
        "# Very beginner-friendly version!\n",
        "# This script:\n",
        "# 1. Loads the Digits dataset\n",
        "# 2. Trains Linear SVM and RBF SVM\n",
        "# 3. Performs Grid Search for best C and gamma\n",
        "# 4. Saves a heatmap of accuracies\n",
        "# 5. Shows support vectors in PCA 2D\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import (\n",
        "    StratifiedKFold,\n",
        "    GridSearchCV,\n",
        "    cross_val_score,\n",
        "    train_test_split\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "\n",
        "# Create output folder if missing\n",
        "def ensure_output_folder():\n",
        "    os.makedirs(\"outputs/svm\", exist_ok=True)\n",
        "\n",
        "\n",
        "# Draw heatmap of accuracy values\n",
        "def draw_heatmap(acc_matrix, C_values, gamma_values, title, save_path):\n",
        "    plt.figure()\n",
        "    plt.imshow(acc_matrix, origin=\"lower\", aspect=\"auto\")\n",
        "    plt.colorbar(label=\"CV Accuracy\")\n",
        "    plt.xticks(np.arange(len(gamma_values)), gamma_values)\n",
        "    plt.yticks(np.arange(len(C_values)), C_values)\n",
        "    plt.xlabel(\"Gamma value\")\n",
        "    plt.ylabel(\"C value\")\n",
        "    plt.title(title)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=200)\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "# Plot support vectors after PCA reduction\n",
        "def plot_support_vectors(model, X_2d, y, title, save_path):\n",
        "    plt.figure()\n",
        "\n",
        "    # Plot each digit class\n",
        "    for digit in np.unique(y):\n",
        "        mask = (y == digit)\n",
        "        plt.scatter(X_2d[mask, 0], X_2d[mask, 1], s=12, edgecolors='k',\n",
        "                    alpha=0.6, label=str(digit))\n",
        "\n",
        "    # Highlight support vectors\n",
        "    sv = model.support_vectors_\n",
        "    plt.scatter(sv[:, 0], sv[:, 1], s=70, facecolors='none',\n",
        "                edgecolors='red', linewidths=1.5, label=\"Support Vectors\")\n",
        "\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"PCA Component 1\")\n",
        "    plt.ylabel(\"PCA Component 2\")\n",
        "    plt.legend(fontsize=7, ncol=2)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=200)\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    ensure_output_folder()\n",
        "\n",
        "    # ===============================\n",
        "    # 1. Load Digits dataset\n",
        "    # ===============================\n",
        "    X, y = load_digits(return_X_y=True)\n",
        "\n",
        "    # Scale the data (important for SVM!)\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    # Cross-validation setup\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "    # ===============================\n",
        "    # 2. Baseline: Linear SVM\n",
        "    # ===============================\n",
        "    linear_svm = SVC(kernel=\"linear\", C=1.0)\n",
        "    linear_scores = cross_val_score(linear_svm, X_scaled, y, cv=cv, scoring=\"accuracy\")\n",
        "\n",
        "    # ===============================\n",
        "    # 3. Baseline: RBF SVM\n",
        "    # ===============================\n",
        "    rbf_svm = SVC(kernel=\"rbf\", C=1.0, gamma=\"scale\")\n",
        "    rbf_scores = cross_val_score(rbf_svm, X_scaled, y, cv=cv, scoring=\"accuracy\")\n",
        "\n",
        "    print(f\"\\nLinear SVM accuracy: {linear_scores.mean():.4f} ± {linear_scores.std():.4f}\")\n",
        "    print(f\"RBF SVM accuracy:    {rbf_scores.mean():.4f} ± {rbf_scores.std():.4f}\")\n",
        "\n",
        "    # ===============================\n",
        "    # 4. Grid Search (C and gamma)\n",
        "    # ===============================\n",
        "    param_grid = {\n",
        "        \"C\": [0.1, 1, 10, 100],\n",
        "        \"gamma\": [0.001, 0.01, 0.1, 1.0]\n",
        "    }\n",
        "\n",
        "    print(\"\\nRunning Grid Search... (this may take a few seconds)\")\n",
        "    grid_search = GridSearchCV(\n",
        "        SVC(kernel=\"rbf\"),\n",
        "        param_grid=param_grid,\n",
        "        cv=cv,\n",
        "        scoring=\"accuracy\",\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    grid_search.fit(X_scaled, y)\n",
        "\n",
        "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "    print(f\"Best CV accuracy: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "    # Convert results to matrix for heatmap\n",
        "    mean_scores = grid_search.cv_results_[\"mean_test_score\"]\n",
        "    score_matrix = mean_scores.reshape(len(param_grid[\"C\"]), len(param_grid[\"gamma\"]))\n",
        "\n",
        "    draw_heatmap(\n",
        "        score_matrix,\n",
        "        param_grid[\"C\"],\n",
        "        param_grid[\"gamma\"],\n",
        "        \"RBF SVM Grid Search Accuracy\",\n",
        "        \"outputs/svm/heatmap_rbf.png\"\n",
        "    )\n",
        "\n",
        "    print(\"\\nSaved: outputs/svm/heatmap_rbf.png\")\n",
        "\n",
        "    # ===============================\n",
        "    # 5. PCA + Support Vector Plots\n",
        "    # ===============================\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_scaled, y, test_size=0.25, stratify=y, random_state=42\n",
        "    )\n",
        "\n",
        "    pca = PCA(n_components=2, random_state=42)\n",
        "    X_train_2d = pca.fit_transform(X_train)\n",
        "\n",
        "    # Train best models on PCA data\n",
        "    best_linear = SVC(kernel=\"linear\", C=1.0).fit(X_train_2d, y_train)\n",
        "    best_rbf = SVC(\n",
        "        kernel=\"rbf\",\n",
        "        C=grid_search.best_params_[\"C\"],\n",
        "        gamma=grid_search.best_params_[\"gamma\"]\n",
        "    ).fit(X_train_2d, y_train)\n",
        "\n",
        "    plot_support_vectors(\n",
        "        best_linear, X_train_2d, y_train,\n",
        "        \"Linear SVM Support Vectors (PCA 2D)\",\n",
        "        \"outputs/svm/sv_linear.png\"\n",
        "    )\n",
        "\n",
        "    plot_support_vectors(\n",
        "        best_rbf, X_train_2d, y_train,\n",
        "        \"RBF SVM Support Vectors (PCA 2D)\",\n",
        "        \"outputs/svm/sv_rbf.png\"\n",
        "    )\n",
        "\n",
        "    print(\"Saved: outputs/svm/sv_linear.png, outputs/svm/sv_rbf.png\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4xrCXxTap30",
        "outputId": "2de31075-ed97-4fe7-fe2a-15258db7337e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Linear SVM accuracy: 0.9794 ± 0.0033\n",
            "RBF SVM accuracy:    0.9839 ± 0.0060\n",
            "\n",
            "Running Grid Search... (this may take a few seconds)\n",
            "Best parameters: {'C': 10, 'gamma': 0.01}\n",
            "Best CV accuracy: 0.9827\n",
            "\n",
            "Saved: outputs/svm/heatmap_rbf.png\n",
            "Saved: outputs/svm/sv_linear.png, outputs/svm/sv_rbf.png\n"
          ]
        }
      ]
    }
  ]
}